/**
 * ü§ñ Smart Scraper with Fallback
 * Only scrapes real custom domains, skips directories/social media
 */

import { isBlacklistedDomain } from "@/lib/search/domainClassifier";
import { batchScrapeWithCheerio } from "./cheerio-scraper";

export interface ScraperResult {
  success: boolean;
  gel?: number;
  pedicure?: number;
  acrylic?: number;
  services?: Array<{ name: string; price: number }>;
  source: "scraped" | "estimated" | "skipped";
  reason?: string;
}

/**
 * Smart scrape decision: ULTRA STRICT - Only scrape validated real business websites
 */
export function shouldScrape(url: string, websiteScore?: number): {
  shouldScrape: boolean;
  reason: string;
} {
  if (!url || url === "#") {
    return {
      shouldScrape: false,
      reason: "No URL provided",
    };
  }

  // HARD BLOCK: Check blocked domains
  if (isBlacklistedDomain(url)) {
    console.log(`   ‚ö†Ô∏è  Blocked directory domain - skipping scrape`);
    return {
      shouldScrape: false,
      reason: "Blocked domain (directory/social media/review site)",
    };
  }

  // STRICT: Only scrape if website was validated with score >= 20
  if (websiteScore !== undefined && websiteScore < 20) {
    console.log(`   ‚ùå Invalid website (score: ${websiteScore} < 20) - skipping scrape`);
    return {
      shouldScrape: false,
      reason: `Invalid website (score: ${websiteScore} < 20)`,
    };
  }

  return {
    shouldScrape: true,
    reason: "Valid custom domain (score >= 20)",
  };
}

/**
 * Scrape a single website (with ULTRA STRICT filtering)
 */
export async function smartScrape(
  name: string,
  url: string,
  websiteScore?: number
): Promise<ScraperResult> {
  // ULTRA STRICT: Check if we should scrape
  const decision = shouldScrape(url, websiteScore);

  if (!decision.shouldScrape) {
    console.log(`‚è≠Ô∏è  Skipping scrape for ${name}: ${decision.reason}`);
    return {
      success: false,
      source: "skipped",
      reason: decision.reason,
    };
  }

  // Only scrape validated custom domains
  console.log(`üåê Scraping ${name}: ${url} (validated, score: ${websiteScore || 'unknown'})`);

  try {
    const scrapedData = await batchScrapeWithCheerio(
      [{ name, website: url }],
      1
    );

    const result = scrapedData.get(name);

    if (result && result.success) {
      console.log(`‚úÖ Successfully scraped ${name}`);
      return {
        success: true,
        gel: result.gel,
        pedicure: result.pedicure,
        acrylic: result.acrylic,
        services: result.services,
        source: "scraped",
      };
    }

    console.log(`‚ö†Ô∏è  Scraping failed for ${name}, fallback to estimation`);
    return {
      success: false,
      source: "estimated",
      reason: "Scraping failed - content not extractable",
    };
  } catch (error: any) {
    console.error(`‚ùå Scraping error for ${name}: ${error.message}`);
    return {
      success: false,
      source: "estimated",
      reason: `Scraping error: ${error.message}`,
    };
  }
}

/**
 * Batch scrape with ULTRA STRICT filtering
 */
export async function batchSmartScrape(
  targets: Array<{ name: string; website: string; websiteScore?: number }>
): Promise<Map<string, ScraperResult>> {
  const results = new Map<string, ScraperResult>();

  // ULTRA STRICT: Filter targets - only scrape validated domains with score >= 20
  const scrapableTargets = targets.filter((target) =>
    shouldScrape(target.website, target.websiteScore).shouldScrape
  );

  const skippedTargets = targets.filter(
    (target) => !shouldScrape(target.website, target.websiteScore).shouldScrape
  );

  console.log(
    `\nü§ñ ULTRA STRICT Scraper: ${scrapableTargets.length} validated, ${skippedTargets.length} rejected/blocked`
  );

  // Mark skipped targets
  for (const target of skippedTargets) {
    const decision = shouldScrape(target.website, target.websiteScore);
    console.log(`‚è≠Ô∏è  ${target.name}: ${decision.reason}`);

    results.set(target.name, {
      success: false,
      source: "skipped",
      reason: decision.reason,
    });
  }

  // Scrape only validated targets
  if (scrapableTargets.length > 0) {
    try {
      const scrapedData = await batchScrapeWithCheerio(scrapableTargets, 2);

      for (const target of scrapableTargets) {
        const result = scrapedData.get(target.name);

        if (result && result.success) {
          results.set(target.name, {
            success: true,
            gel: result.gel,
            pedicure: result.pedicure,
            acrylic: result.acrylic,
            services: result.services,
            source: "scraped",
          });
        } else {
          results.set(target.name, {
            success: false,
            source: "estimated",
            reason: "Content not extractable",
          });
        }
      }
    } catch (error: any) {
      console.error(`‚ùå Batch scraping error: ${error.message}`);

      // Mark all as failed (fallback to estimation)
      for (const target of scrapableTargets) {
        if (!results.has(target.name)) {
          results.set(target.name, {
            success: false,
            source: "estimated",
            reason: `Scraping error: ${error.message}`,
          });
        }
      }
    }
  }

  return results;
}

/**
 * Puppeteer hook (stub for future implementation)
 * This would run on a separate server, not on Vercel
 */
export async function scrapWithPuppeteer(
  url: string
): Promise<ScraperResult> {
  // Stub implementation
  console.log(
    `üé≠ Puppeteer scraping not available (requires separate server)`
  );

  return {
    success: false,
    source: "estimated",
    reason: "Puppeteer not available on serverless",
  };
}

/**
 * Estimate prices based on price tier
 */
export function estimatePrices(priceLevel: number): {
  gel: number;
  pedicure: number;
  acrylic: number;
} {
  const estimates: Record<
    number,
    { gel: number; pedicure: number; acrylic: number }
  > = {
    1: { gel: 30, pedicure: 35, acrylic: 45 },
    2: { gel: 40, pedicure: 45, acrylic: 55 },
    3: { gel: 50, pedicure: 60, acrylic: 70 },
    4: { gel: 65, pedicure: 80, acrylic: 90 },
  };

  return estimates[priceLevel] || estimates[2];
}

